# -*- coding: utf-8 -*-
"""
Backend API cho Chatbot D∆∞·ª£c li·ªáu C·ªï truy·ªÅn (Ki·∫øn tr√∫c CRAG - Hugging Face)
S·ª≠ d·ª•ng FastAPI v√† LangGraph.
File n√†y c≈©ng c√≥ th·ªÉ ƒë∆∞·ª£c ch·∫°y tr·ª±c ti·∫øp ƒë·ªÉ ki·ªÉm tra logic.
"""
import os
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from typing import List, Literal, Any

# LangChain components
from langchain_community.document_loaders import JSONLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEndpoint
from langchain_community.tools import DuckDuckGoSearchRun
from langchain.prompts import ChatPromptTemplate, PromptTemplate
from langchain.schema import Document, StrOutputParser

# LangGraph components
from langgraph.graph import StateGraph, END, START
from typing_extensions import TypedDict

# --- Kh·ªüi t·∫°o ·ª©ng d·ª•ng FastAPI ---
app = FastAPI(
    title="API Chatbot D∆∞·ª£c li·ªáu (CRAG - Hugging Face)",
    description="API cho chatbot n√¢ng cao ch·ªâ s·ª≠ d·ª•ng Hugging Face.",
    version="2.6.0",
)

# --- ƒê·ªãnh nghƒ©a model cho request v√† response ---
class ChatRequest(BaseModel):
    query: str
    huggingface_api_key: str

class ChatResponse(BaseModel):
    generation: str
    documents: List[str]

# --- Bi·∫øn to√†n c·ª•c ƒë·ªÉ l∆∞u tr·ªØ c√°c th√†nh ph·∫ßn ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω tr∆∞·ªõc ---
retriever = None
crag_app = None

# --- ƒê·ªãnh nghƒ©a State v√† c√°c Node c·ªßa Graph ---
class GraphState(TypedDict):
    question: str
    generation: str
    documents: List[Document]
    llm: Any

def retrieve_node(state):
    print("---NODE: RETRIEVE---")
    documents = retriever.invoke(state["question"])
    return {"documents": documents}

def grade_documents_node(state):
    print("---NODE: GRADE DOCUMENTS---")
    question = state["question"]
    documents = state["documents"]
    llm = state["llm"]

    system = "B·∫°n l√† ng∆∞·ªùi ƒë√°nh gi√° m·ª©c ƒë·ªô li√™n quan c·ªßa t√†i li·ªáu v·ªõi c√¢u h·ªèi. Ch·ªâ tr·∫£ l·ªùi 'yes' n·∫øu t√†i li·ªáu li√™n quan, ng∆∞·ª£c l·∫°i tr·∫£ l·ªùi 'no'."
    prompt = ChatPromptTemplate.from_messages([
        ("system", system),
        ("human", "T√†i li·ªáu:\n\n{document}\n\nC√¢u h·ªèi: {question}"),
    ])
    grader = prompt | llm | StrOutputParser()
    
    filtered_docs = []
    for d in documents:
        score = grader.invoke({"question": question, "document": d.page_content})
        grade = score.strip().lower()
        if 'yes' in grade:
            print("---GRADE: RELEVANT---")
            filtered_docs.append(d)
        else:
            print("---GRADE: NOT RELEVANT---")
    return {"documents": filtered_docs}

def transform_query_node(state):
    print("---NODE: TRANSFORM QUERY---")
    question = state["question"]
    llm = state["llm"]

    system = "B·∫°n l√† ng∆∞·ªùi vi·∫øt l·∫°i c√¢u h·ªèi ƒë·ªÉ t·ªëi ∆∞u h√≥a cho t√¨m ki·∫øm web."
    prompt = ChatPromptTemplate.from_messages([
        ("system", system),
        ("human", "C√¢u h·ªèi ban ƒë·∫ßu: {question}\n\nH√£y t·∫°o ra m·ªôt c√¢u h·ªèi c·∫£i ti·∫øn:"),
    ])
    rewriter = prompt | llm | StrOutputParser()
    better_question = rewriter.invoke({"question": question})
    return {"question": better_question}

def web_search_node(state):
    print("---NODE: WEB SEARCH---")
    question = state["question"]
    documents = state["documents"]
    
    web_search_tool = DuckDuckGoSearchRun()
    web_results = web_search_tool.run(question)
    web_results_doc = Document(page_content=web_results)
    if documents is None:
        documents = []
    documents.append(web_results_doc)
    return {"documents": documents}

def generate_node(state):
    print("---NODE: GENERATE---")
    question = state["question"]
    documents = state["documents"]
    llm = state["llm"]
    
    prompt_template = PromptTemplate.from_template(
        "D·ª±a v√†o ng·ªØ c·∫£nh sau ƒë√¢y ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi b·∫±ng ti·∫øng Vi·ªát.\n\nNg·ªØ c·∫£nh: {context}\n\nC√¢u h·ªèi: {question}\n\nC√¢u tr·∫£ l·ªùi:"
    )
    rag_chain = prompt_template | llm | StrOutputParser()
    generation = rag_chain.invoke({"context": documents, "question": question})
    return {"generation": generation}

def decide_to_generate_edge(state):
    print("---EDGE: DECIDE TO GENERATE---")
    if not state["documents"]:
        return "transform_query"
    else:
        return "generate"

def load_and_prepare_rag():
    global retriever, crag_app
    
    jq_schema = '.[] | "T√™n v·ªã thu·ªëc: " + .name + ". Chi ti·∫øt: " + .detail + ". T√≥m t·∫Øt: " + .summaried'
    loader = JSONLoader(file_path='./merged_data.json', jq_schema=jq_schema, text_content=True)
    documents = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    chunks = text_splitter.split_documents(documents)
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    vectorstore = FAISS.from_documents(chunks, embeddings)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 4})
    print("‚úÖ Retriever ƒë√£ s·∫µn s√†ng!")

    workflow = StateGraph(GraphState)
    workflow.add_node("retrieve", retrieve_node)
    workflow.add_node("grade_documents", grade_documents_node)
    workflow.add_node("transform_query", transform_query_node)
    workflow.add_node("web_search", web_search_node)
    workflow.add_node("generate", generate_node)
    
    workflow.add_edge(START, "retrieve")
    workflow.add_edge("retrieve", "grade_documents")
    workflow.add_conditional_edges("grade_documents", decide_to_generate_edge, {
        "transform_query": "transform_query",
        "generate": "generate"
    })
    workflow.add_edge("transform_query", "web_search")
    workflow.add_edge("web_search", "generate")
    workflow.add_edge("generate", END)

    crag_app = workflow.compile()
    print("‚úÖ Graph ƒë√£ ƒë∆∞·ª£c bi√™n d·ªãch v√† s·∫µn s√†ng!")

@app.on_event("startup")
async def startup_event():
    print("üöÄ Server ƒëang kh·ªüi ƒë·ªông v√† chu·∫©n b·ªã d·ªØ li·ªáu...")
    load_and_prepare_rag()

@app.post("/chat")
async def chat_with_bot(request: ChatRequest):
    if not retriever or not crag_app:
        raise HTTPException(status_code=503, detail="H·ªá th·ªëng ch∆∞a s·∫µn s√†ng.")
    
    llm = HuggingFaceEndpoint(
        repo_id="meta-llama/Llama-2-70b-hf",
        temperature=0.1,
        max_new_tokens=1024,
        repetition_penalty=1.2,
        huggingfacehub_api_token=request.huggingface_api_key
    )
    
    try:
        inputs = {"question": request.query, "llm": llm}
        final_state = crag_app.invoke(inputs)
        doc_contents = [doc.page_content for doc in final_state.get('documents', [])]
        
        return {
            "generation": final_state.get('generation', "Kh√¥ng th·ªÉ t·∫°o c√¢u tr·∫£ l·ªùi."),
            "documents": doc_contents
        }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"L·ªói trong qu√° tr√¨nh x·ª≠ l√Ω c·ªßa graph: {e}")

# --- C·∫¨P NH·∫¨T: Th√™m h√†m ch√≠nh ƒë·ªÉ ch·∫°y th·ª≠ nghi·ªám ---
if __name__ == "__main__":
    # H√†m n√†y ch·ªâ ch·∫°y khi b·∫°n th·ª±c thi file: `python backend_app.py`
    
    print("--- CH·∫†Y TH·ª¨ NGHI·ªÜM BACKEND ---")
    
    # 1. Ki·ªÉm tra API Key t·ª´ bi·∫øn m√¥i tr∆∞·ªùng
    api_key = os.getenv("HUGGINGFACEHUB_API_TOKEN")
    if not api_key:
        print("\n‚ùå L·ªói: Vui l√≤ng thi·∫øt l·∫≠p bi·∫øn m√¥i tr∆∞·ªùng HUGGINGFACEHUB_API_TOKEN tr∆∞·ªõc khi ch·∫°y.")
        print("V√≠ d·ª•: export HUGGINGFACEHUB_API_TOKEN='hf_your_token_here'")
    else:
        # 2. T·∫£i d·ªØ li·ªáu v√† bi√™n d·ªãch graph
        load_and_prepare_rag()
        
        # 3. Kh·ªüi t·∫°o LLM
        llm = HuggingFaceEndpoint(
            repo_id="meta-llama/Llama-2-70b-hf",
            temperature=0.1,
            max_new_tokens=1024,
            repetition_penalty=1.2,
            huggingfacehub_api_token=api_key
        )

        # 4. ƒê·∫∑t c√¢u h·ªèi th·ª≠ nghi·ªám
        test_query = "v·ªã thu·ªëc n√†o c√≥ t√°c d·ª•ng b·ªï huy·∫øt v√† c·∫ßm m√°u?"
        print(f"\n‚ùì C√¢u h·ªèi th·ª≠ nghi·ªám: {test_query}")

        # 5. Ch·∫°y Graph
        inputs = {"question": test_query, "llm": llm}
        final_state = crag_app.invoke(inputs)

        # 6. In k·∫øt qu·∫£
        print("\n\n--- K·∫æT QU·∫¢ CU·ªêI C√ôNG ---")
        print("\nüí¨ C√¢u tr·∫£ l·ªùi c·ªßa Bot:")
        print(final_state.get('generation', "Kh√¥ng c√≥ c√¢u tr·∫£ l·ªùi."))
        
        print("\nüìö C√°c ngu·ªìn t√†i li·ªáu ƒë∆∞·ª£c s·ª≠ d·ª•ng:")
        source_docs = final_state.get('documents', [])
        if source_docs:
            for i, doc in enumerate(source_docs):
                print(f"--- Ngu·ªìn {i+1} ---")
                print(doc.page_content)
                print("-" * 20)
        else:
            print("Kh√¥ng c√≥ ngu·ªìn t√†i li·ªáu n√†o ƒë∆∞·ª£c s·ª≠ d·ª•ng.")

"""
--- K·∫æT QU·∫¢ M·∫™U KHI CH·∫†Y TH·ª¨ NGHI·ªÜM (python backend_app.py) ---

--- CH·∫†Y TH·ª¨ NGHI·ªÜM BACKEND ---
üöÄ Server ƒëang kh·ªüi ƒë·ªông v√† chu·∫©n b·ªã d·ªØ li·ªáu...
‚úÖ Retriever ƒë√£ s·∫µn s√†ng!
‚úÖ Graph ƒë√£ ƒë∆∞·ª£c bi√™n d·ªãch v√† s·∫µn s√†ng!

‚ùì C√¢u h·ªèi th·ª≠ nghi·ªám: v·ªã thu·ªëc n√†o c√≥ t√°c d·ª•ng b·ªï huy·∫øt v√† c·∫ßm m√°u?
---NODE: RETRIEVE---
---NODE: GRADE DOCUMENTS---
---GRADE: RELEVANT---
---GRADE: RELEVANT---
---GRADE: RELEVANT---
---GRADE: RELEVANT---
---EDGE: DECIDE TO GENERATE---
---NODE: GENERATE---


--- K·∫æT QU·∫¢ CU·ªêI C√ôNG ---

üí¨ C√¢u tr·∫£ l·ªùi c·ªßa Bot:
D·ª±a v√†o ng·ªØ c·∫£nh ƒë∆∞·ª£c cung c·∫•p, c√°c v·ªã thu·ªëc c√≥ t√°c d·ª•ng b·ªï huy·∫øt v√† c·∫ßm m√°u bao g·ªìm:
1.  **A GIAO (Ph√≥ tri giao):** T√°c d·ª•ng ch√≠nh l√† B·ªï Huy·∫øt v√† C·∫ßm M√°u, ch·ªØa c√°c ch·ª©ng xu·∫•t huy·∫øt v√† c√°c b·ªánh do huy·∫øt kh√¥.
2.  **B·∫†CH TH∆Ø·ª¢C:** C√≥ kh·∫£ nƒÉng D∆∞·ª°ng Huy·∫øt, Li·ªÖm √Çm, d√πng ƒë·ªÉ nu√¥i m√°u.
3.  **ƒêAN-S√ÇM:** C√¥ng hi·ªáu ƒë∆∞·ª£c v√≠ nh∆∞ b√†i T·ª© v·∫≠t thang, chuy√™n tr·ªã c√°c b·ªánh v·ªÅ huy·∫øt.
4.  **H√Ä-DI·ªÜP (L√° sen):** Gi√∫p c·∫ßm c√°c ch·ª©ng xu·∫•t huy·∫øt nh∆∞ th·ªï huy·∫øt, bƒÉng huy·∫øt.

üìö C√°c ngu·ªìn t√†i li·ªáu ƒë∆∞·ª£c s·ª≠ d·ª•ng:
--- Ngu·ªìn 1 ---
T√™n v·ªã thu·ªëc: Ph√≥ tri giao, Ch√¢n a giao, L∆∞ b√¨ giao, A giao ch√¢u, Sao a giao, Th∆∞·ª£ng a giao, √î giao, B√¨ giao. Chi ti·∫øt: Thu·ªëc n√†y t√™n l√† A GIAO, t√°c d·ª•ng l√† ch·ªØa c√°c ch·ª©ng xu·∫•t huy·∫øt (ƒë·ªï m√°u cam, ti·ªÉu/ƒë·∫°i ti·ªán ra huy·∫øt, bƒÉng huy·∫øt), c√°c ch·ª©ng do huy·∫øt kh√¥ (ƒëau l∆∞ng, kinh nguy·ªát kh√¥ng ƒë·ªÅu) v√† ƒë·ªông thai.. T√≥m t·∫Øt: T√°c d·ª•ng ch√≠nh n·ªïi b·∫≠t l√† **B·ªï Huy·∫øt v√† C·∫ßm M√°u**. Nh·ªù v√†o t√≠nh v·ªã ng·ªçt, t√≠nh b√¨nh, kh√¥ng ƒë·ªôc, A Giao c√≥ kh·∫£ nƒÉng t∆∞ √¢m, nhu·∫≠n t√°o, chuy√™n tr·ªã c√°c ch·ª©ng ho khan do ph·∫ø t√°o, c√°c lo·∫°i xu·∫•t huy·∫øt do huy·∫øt nhi·ªát ho·∫∑c h∆∞ t·ªïn, v√† an thai. Kh√¥ng c√≥ t√°c d·ª•ng ph·ª• ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p, tuy nhi√™n c·∫ßn l∆∞u √Ω: ng∆∞·ªùi c√≥ t·ª≥ v·ªã h∆∞ y·∫øu, ƒÉn u·ªëng kh√≥ ti√™u, ho·∫∑c ƒëang b·ªã ti√™u ch·∫£y th√¨ kh√¥ng n√™n d√πng. V·ªã thu·ªëc n√†y k·ªµ (s·ª£) ƒê·∫°i ho√†ng.
--------------------
... (c√°c ngu·ªìn t√†i li·ªáu li√™n quan kh√°c s·∫Ω ƒë∆∞·ª£c li·ªát k√™ ·ªü ƒë√¢y) ...
"""
