# -*- coding: utf-8 -*-
"""
Backend API cho Chatbot D∆∞·ª£c li·ªáu C·ªï truy·ªÅn
S·ª≠ d·ª•ng FastAPI ƒë·ªÉ cung c·∫•p endpoint cho vi·ªác h·ªèi ƒë√°p.
"""

import os
from fastapi import FastAPI, HTTPException, Depends
from pydantic import BaseModel
from typing import Optional

from langchain_community.document_loaders import JSONLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain_huggingface import HuggingFaceEndpoint
from langchain.prompts import PromptTemplate

# --- Kh·ªüi t·∫°o ·ª©ng d·ª•ng FastAPI ---
app = FastAPI(
    title="API Chatbot D∆∞·ª£c li·ªáu",
    description="API cho ph√©p h·ªèi ƒë√°p d·ª±a tr√™n ng·ªØ li·ªáu y h·ªçc c·ªï truy·ªÅn.",
    version="1.0.0",
)

# --- ƒê·ªãnh nghƒ©a model cho request v√† response ---
class ChatRequest(BaseModel):
    query: str
    api_token: Optional[str] = None

class ChatResponse(BaseModel):
    result: str
    source_documents: list[dict]

# --- Bi·∫øn to√†n c·ª•c ƒë·ªÉ l∆∞u tr·ªØ Retriever v√† Prompt ---
retriever = None
prompt_template = None

# --- H√†m t·∫£i v√† chu·∫©n b·ªã Retriever ---
def load_rag_dependencies():
    """
    T·∫£i d·ªØ li·ªáu, embed, kh·ªüi t·∫°o retriever v√† prompt.
    H√†m n√†y ƒë∆∞·ª£c g·ªçi m·ªôt l·∫ßn khi server kh·ªüi ƒë·ªông.
    """
    global retriever, prompt_template
    
    # 1. T·∫£i d·ªØ li·ªáu t·ª´ file JSON
    jq_schema = '.[] | "T√™n v·ªã thu·ªëc: " + .name + ". Chi ti·∫øt: " + .detail + ". T√≥m t·∫Øt: " + .summaried'
    loader = JSONLoader(
        file_path='./merged_data.json',
        jq_schema=jq_schema,
        text_content=True
    )
    documents = loader.load()

    # 2. Chia nh·ªè vƒÉn b·∫£n
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    chunks = text_splitter.split_documents(documents)

    # 3. T·∫°o embeddings
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    )

    # 4. L∆∞u v√†o Vector Store v√† t·∫°o retriever
    vectorstore = FAISS.from_documents(chunks, embeddings)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
    
    # *** S·ª¨A L·ªñI: ƒê∆°n gi·∫£n h√≥a m·∫´u prompt ƒë·ªÉ tr√°nh l·∫∑p ***
    template = """
    D·ª±a v√†o ng·ªØ c·∫£nh sau ƒë√¢y ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi m·ªôt c√°ch ng·∫Øn g·ªçn v√† ch√≠nh x√°c.

    Ng·ªØ c·∫£nh: {context}

    C√¢u h·ªèi: {question}

    C√¢u tr·∫£ l·ªùi:
    """
    prompt_template = PromptTemplate(template=template, input_variables=["context", "question"])
    
    print("‚úÖ Retriever v√† Prompt ƒë√£ s·∫µn s√†ng!")

# --- S·ª± ki·ªán kh·ªüi ƒë·ªông server ---
@app.on_event("startup")
async def startup_event():
    print("üöÄ Server ƒëang kh·ªüi ƒë·ªông v√† chu·∫©n b·ªã d·ªØ li·ªáu...")
    load_rag_dependencies()

# --- API Endpoint ƒë·ªÉ chat ---
@app.post("/chat", response_model=ChatResponse)
async def chat_with_bot(request: ChatRequest):
    if not retriever or not prompt_template:
        raise HTTPException(status_code=503, detail="H·ªá th·ªëng ch∆∞a s·∫µn s√†ng, vui l√≤ng th·ª≠ l·∫°i sau.")
    
    if not request.api_token:
        raise HTTPException(status_code=400, detail="Hugging Face API Token l√† b·∫Øt bu·ªôc.")

    try:
        # Kh·ªüi t·∫°o LLM v·ªõi token ƒë∆∞·ª£c cung c·∫•p trong request
        llm = HuggingFaceEndpoint(
            repo_id="meta-llama/Llama-2-70b-hf",
            temperature=0.1,
            max_new_tokens=1024,
            # *** S·ª¨A L·ªñI: Th√™m tham s·ªë ch·ªëng l·∫∑p ***
            repetition_penalty=1.2,
            huggingfacehub_api_token=request.api_token
        )
        
        # Th√™m prompt t√πy ch·ªânh v√†o chu·ªói RAG
        chain_type_kwargs = {"prompt": prompt_template}
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=retriever,
            chain_type_kwargs=chain_type_kwargs,
            return_source_documents=True
        )

        response = qa_chain.invoke({"query": request.query})
        
        # Chuy·ªÉn ƒë·ªïi Document objects th√†nh dict ƒë·ªÉ t∆∞∆°ng th√≠ch JSON
        source_docs = [
            {"page_content": doc.page_content, "metadata": doc.metadata} 
            for doc in response.get('source_documents', [])
        ]
        
        return ChatResponse(
            result=response.get('result', "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y c√¢u tr·∫£ l·ªùi."),
            source_documents=source_docs
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# --- Endpoint ki·ªÉm tra s·ª©c kh·ªèe ---
@app.get("/")
def read_root():
    return {"status": "API Chatbot ƒëang ho·∫°t ƒë·ªông!"}
